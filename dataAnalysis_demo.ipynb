{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d500d0fb-09c7-49df-8f9e-a694e3f6ba37",
   "metadata": {},
   "source": [
    "# Guide to using spectrum module for data analysis\n",
    "\n",
    "This guide will aid you in using the functionality of the spectrum module to read, process, and analyse optical and magneto-optical spectral data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec3c86df-7d13-4a2e-bae6-d011e5bfbd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminaries\n",
    "from spectrum import *\n",
    "import os\n",
    "from pathlib import Path\n",
    "current_path = Path.cwd()\n",
    "\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "# Data paths\n",
    "path001 = os.path.join(current_path, \"Data\", \"Facet_001\")\n",
    "path100 = os.path.join(current_path, \"Data\", \"Facet_100\")"
=======
    "# MagnetoOptics paths\n",
    "path001 = os.path.join(current_path, \"Data\", \"Magneto-optics\", \"Facet_001\")\n",
    "path100 = os.path.join(current_path, \"Data\", \"Magneto-optics\", \"Facet_100\")\n",
    "\n",
    "# Optics paths\n",
    "pathAna = os.path.join(current_path, \"Data\", \"Optics\", \"Ana\", \"ZrSiTe\")\n",
    "pathDavid = os.path.join(current_path, \"Data\", \"Optics\", \"David\", \"raw_data\")\n",
    "pathGold = os.path.join(current_path, \"Data\", \"Optics\", \"Reference_gold.dat\")\n",
    "\n",
    "# EuBased paths\n",
    "pathTR1 = os.path.join(current_path, \"Data\", \"EuBased\", \"EuCd2P2\", \"TR1_David\")\n",
    "pathTR2 = os.path.join(current_path, \"Data\", \"EuBased\", \"EuCd2P2\", \"TR2_Jan\")"
>>>>>>> cb2a4cd (Moved files)
=======
    "# Data paths\n",
    "path001 = os.path.join(current_path, \"Data\", \"Facet_001\")\n",
    "path100 = os.path.join(current_path, \"Data\", \"Facet_100\")"
>>>>>>> 3d319f1 (Updated demos)
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60459d4e",
   "metadata": {},
   "source": [
    "## Getting started: Initialisation\n",
    "The macro takes five main inputs: the path(s) to the folder of measurement data, ``data_path``; the path to the folder of reference data, ``ref_path``; the units, ``units``; a check for whether the file names contain magnetic fields or temperatures, ``col_names``; and a check for whether the data should be normalised by using two zero-field references or using reference files matched to the measurement files, ``zero_field``. A description of these inputs, as well as the type of value they can take, is listed in the table below.\n",
    "\n",
    "| **Variable name** | data_path                | ref_path               | units                    | col_names                                                  | zero_field                  |\n",
    "| -----             | ----                     | ----                   | ----                     | ----                                                       | ----                        |   \n",
    "| **Description**   | Path to measurement data | Path to reference data | Units for the index      | Whether the columns should be field or temperature values  | Whether to use two references or match references to data |\n",
    "| **Type**          | string or array          | string (optional)      | \"cm-1\" or \"meV\" or \"THz\" | \"B\" or \"T\"                                                 |  Boolean                     |\n",
    "\n",
    "### Setting path names\n",
    "The macro is initialised using two inputs: ``data_path`` should be a string or list of strings which are paths to folders of measurement data, while ``ref_path`` should be a string which is the path to a folder of reference data. \n",
    "\n",
    "```python\n",
    "example = Data_macro(data_path, ref_path)\n",
    "```\n",
    "\n",
    "If only ``data_path`` is entered, the macro will assume that the reference data is stored in the same folder as the measurement data.\n",
    "\n",
    "If neither path is entered, the macro will ask for the data path and reference path as user inputs.\n",
    "\n",
    "```python\n",
    "example = Data_macro()\n",
    "```\n",
    "```\n",
    "Enter the path to the measurement data (or drag and drop):\n",
    "Enter the path to the zero-field data (or drag and drop):\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67c53b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for getting path from user input\n",
    "example = Data_macro()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bd1b09",
   "metadata": {},
   "source": [
    "### Setting units\n",
    "By default, the ``units`` variable is set to ``\"cm-1\"``. This can be changed to ``\"meV\"`` or ``\"THz\"`` as follows.\n",
    "\n",
    "```python\n",
    "example = Data_macro(data_path, units=\"meV\")\n",
    "```\n",
    "\n",
    "The macro can also be initialised with ``units`` set to ``None``, in which case the units will be requested as an input from the user.\n",
    "\n",
    "```python\n",
    "example = Data_macro(data_path, units=None)\n",
    "```\n",
    "```\n",
    "Enter the units to be used for the index (cm-1, meV, or THz):\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdab1163",
   "metadata": {},
   "source": [
    "### File-handling variables\n",
    "If ``col_names`` is set to ``\"B\"``, the macro reads magnetic field names from the file names. This is done by assuming that the field is denoted as a string starting with ``a``, ending with ``T``, and with ``p`` replacing the decimal point. For example, ``a03p500T`` indicates a field strength of 3.5 T.\n",
    "\n",
    "If ``col_names`` is set to  ``\"T\"``, the macro reads temperature values from the file names. This is done by assuming that the temperature is the last integer in the file name, excluding the last zero.\n",
    "\n",
    "If ``zero_field`` is set to ``True``, the macro normalises the measurement data using an interpolation between two reference datasets.\n",
    "\n",
    "If ``zero_field`` is set to ``False``, the macro normalises the measurement data using the reference file corresponding to the temperature or magnetic field. If the file names end in ``.cor``, the macro does not perform this normalisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54a8a80",
   "metadata": {},
   "source": [
    "## Using the macro\n",
    "Once the macro is initialised, calling the method Auto returns a dataframe.\n",
    "\n",
    "```python\n",
    "df = example.Auto()\n",
    "```\n",
    "\n",
    "This method returns a dataframe of normalised spectral intensities with the following attributes.\n",
    "\n",
    "* ``df.columns()``: 1D array of magnetic field or temperature values, depending on ``col_names``.\n",
    "* ``df.index()``: 1D array of energy values/wavenumbers. The units are by default cm$^{-1}$ but can be set to meV or THz in the initialisation.\n",
    "* ``df.values()``: 2D array of normalised intensities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54cc392",
   "metadata": {},
   "outputs": [],
   "source": [
    "example001 = Data_macro(path001, units=\"cm-1\", col_names=\"B\", zero_field=True, flag_txt=False)\n",
    "df = example001.Auto()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfffb489-5ed9-4f50-a2fa-17cd212d05fe",
   "metadata": {},
   "source": [
    "## Advanced initialisation\n",
    "As well as the five inputs described in the first section, there are a further six inputs that can be used to control how data is processed. All of these inputs are optional. A full list of the inputs, as well as the type of value they can take and their default value, is listed in the table below.\n",
    "\n",
    "| **Variable name** | auto                                            | data_head                                       | ref_head                                         | flag_txt                          | as_folder                                         | high_to_low                                                           |        \n",
    "| -----             | ----                                            | ----                                           | ----                                             | ----                              | ----                                              | ----                                                                  |\n",
    "| **Description**   | Whether the simpler \"Auto\" method should be used | Method to read data file headers              | Method to read reference file headers            | Add \"txt_files\" to each path name | Whether the references are stored in the same folders as the data | Whether to adjust baselines high-to-low or low-to-high, or get user input |\n",
    "| **Type**          | Boolean, defaults to True                        | \"all\" or \"none\" or \"check\", defaults to \"none\"| \"all\" or \"none\" or \"check\", defaults to \"none\" | Boolean, defaults to True          | Boolean, defaults to False                                         | Boolean, defaults to None                                                |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c7e6d6-02bc-4b98-947d-6cdeda89937b",
   "metadata": {},
   "source": [
    "### File-handling variables\n",
    "The variables ``data_head`` and ``ref_head`` determine how the headers in the measurement and reference files are respectively handled. These are initialised in a similar way to ``units`` as described above. Each variable takes three possible values:\n",
    "* ``\"all\"``: Assume all files have headers.\n",
    "* ``\"none\"``: Assume no files have headers.\n",
    "* ``\"check\"``: Check if each file has a header. Note that this method fails for headers which contain only floats, such as those generated by the module. In this case, ``\"all\"`` should be used instead.\n",
    "\n",
    "There are a number of Boolean-type checks as follows.\n",
    "* ``flag_txt``: Set to ``True`` if the readable (.txt) data files are in a separate folder, and ``False`` otherwise.\n",
    "* ``as_folder``: Set to ``True`` if the path entered contains folders for different energy windows, and ``False`` if the path entered is directly a folder of datafiles.\n",
    "* ``sep_paths``: Set to ``True`` if the measurement and reference data are stored in separate paths, and ``False`` if the same path contains both sets of data.\n",
    "* ``high_to_low``: Set to ``True`` if, when merging, the baselines should be adjusted high-to-low, ``False`` if the baselines should be adjusted low-to-high, and ``None`` if this should be a user input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1072f9-3eba-480c-b326-42775650e358",
   "metadata": {},
   "source": [
    "## Some notes about format\n",
    "The module makes the following assumptions about the format of the data files, the file names, and the folders.\n",
    "* Data in different windows (``as_folder = True``) are stored in folders called either ``FIR``, ``HMIR``, ``LMIR``, ``MIR``, or ``NIR``. The names are not case-sensitive. The folders are ordered by energy - in particular, there must be an overlap between the energy windows of consecutive folders.\n",
    "* Data within any given folder covers the same approximate range of energies, though the ranges don't need to be identical.\n",
    "* If the reference data are stored in folders in the same format (``sep_paths = False``), the measurement folders have names like ``run`` or ``sam`` or ``sample``, while the reference folders have names like ``ref``. The names are not case-sensitive.\n",
    "* If the reference data are not stored in the same path as the measurement folders (``sep_paths = True``), the references are stored in just one folder.\n",
    "\n",
    "If these conditions are not met, it may be simpler to use the Auto method for each window (see above) and to merge the windows manually (see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d5ba7-03d2-47e0-89e1-8930b5e198a9",
   "metadata": {},
   "source": [
    "## Using the macro: Single folder\n",
    "Once the macro is initialised, if the data are stored in a single folder (``as_folder = False``), calling the method Do_All returns a dataframe.\n",
    "\n",
    "```python\n",
    "df = example.Do_All()\n",
    "```\n",
    "\n",
    "This method returns a dataframe of normalised spectral intensities with the following attributes.\n",
    "\n",
    "* ``df.columns()``: 1D array of magnetic field or temperature values. Note that the first two columns are the minimum and maximum and the rest are ordered.\n",
    "* ``df.index()``: 1D array of energy values/wavenumbers. The units are by default cm$^{-1}$ but can be set to meV or THz in the initialisation.\n",
    "* ``df.values()``: 2D array of normalised intensities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25200b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "example001 = Data_macro(path001, auto=False, flag_txt=False, as_folder=False, col_names=\"B\", zero_field=True, sep_paths=False, units=\"cm-1\")\n",
    "df = example001.Do_All()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048177a8-4b89-4c18-85aa-50a48017dea8",
   "metadata": {},
   "source": [
    "## Using the macro: Multiple windows\n",
    "Once the macro is initialised, if the data is stored in multiple folders for different windows (``as_folder = True``), calling the method Do_All returns a dataframe of merged windows.\n",
    "\n",
    "The macro will display false colour plots for each window, and will ask whether the baselines should be merged starting from the front of the list (enter ``Y``) or the end of the list (enter ``N``).\n",
    "\n",
    "```python\n",
    "df= example.Do_All()\n",
    "```\n",
    "```\n",
    "Adjust baselines high to low? Y/N: \n",
    "```\n",
    "The user input can be bypassed by setting ``high_to_low`` to either ``True`` or ``False`` when initialising.\n",
    "\n",
    "This method returns a dataframe of corrected or normalised spectral intensities with the following attributes.\n",
    "\n",
    "* ``df.columns()``: 1D array of magnetic field or temperature values. Note that the first two columns are the minimum and maximum and the rest are ordered.\n",
    "* ``df.index()``: 1D array of energy values/wavenumbers. The units are by default cm$^{-1}$ but can be set to meV or THz in the initialisation.\n",
    "* ``df.values()``: 2D array of normalised intensities."
   ]
  },
  {
<<<<<<< HEAD
<<<<<<< HEAD
=======
   "cell_type": "code",
   "execution_count": null,
   "id": "9f87ed4f-ddfd-4df8-a701-7a1bbceb4b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "exampleAna = Data_macro(pathDavid, pathGold, auto=False, flag_txt=False, as_folder=True, col_names=\"T\", zero_field=False, sep_paths=True, units=\"cm-1\", data_head=\"all\")\n",
    "df = exampleAna.Do_All()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3623cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "exampleEuCD2P2 = Data_macro(pathTR1, auto=False, flag_txt=True, as_folder=True, col_names=\"B\", zero_field=False, sep_paths=False, units=\"cm-1\",)\n",
    "df = exampleEuCD2P2.Do_All()\n",
    "df"
   ]
  },
  {
>>>>>>> cb2a4cd (Moved files)
=======
>>>>>>> 3d319f1 (Updated demos)
   "cell_type": "markdown",
   "id": "c9db8a50",
   "metadata": {},
   "source": [
    "# Manual window merging\n",
    "The module is equipped to handle data which is stored in separate folders for measurement and reference data, each of which is stored in folders for different measurement windows. However, suppose that the measurement and reference data are stored in the same folder, with different folders for each measurement window. In this case, it may be best to read the data from each folder separately and merge the windows manually. \n",
    "\n",
    "This section provides a guide for manual reading and merging of different energy windows, as well as demonstrating how the module adjusts the baselines to merge the data.\n",
    "\n",
    "## Reading the data\n",
    "Suppose that a set of magneto-optical data is located by the paths ``pathFIR``, ``pathMIR``, and ``pathNIR``, with each folder containing both measurement data and zero-field references. The dataframes for each folder can be processed and stored in a dictionary as follows. \n",
    "\n",
    "Note that the order of the windows should be either ascending or descending in energy, so that adjacent elements in the dictionary have overlapping energy windows.\n",
    "\n",
    "```python\n",
    "dict = {}\n",
    "inst_FIR = Data_macro(pathFIR, col_names=\"B\", zero_field=True, units=\"cm-1\")\n",
    "dict[\"FIR\"] = inst_FIR.Auto()\n",
    "inst_MIR = Data_macro(pathMIR, col_names=\"B\", zero_field=True, units=\"cm-1\")\n",
    "dict[\"MIR\"] = inst_MIR.Auto()\n",
    "inst_NIR = Data_macro(pathNIR, col_names=\"B\", zero_field=True, units=\"cm-1\")\n",
    "dict[\"NIR\"] = inst_NIR.Auto()\n",
    "```\n",
    "\n",
    "### Handling multiple runs\n",
    "Suppose that one of the windows, FIR, has two (or more) runs, in paths ``pathFIR1`` and ``pathFIR2``, which should be averaged to form the final dataset. This can be handled as follows.\n",
    "\n",
    "```python\n",
    "# The pandas module will be used to average the runs.\n",
    "import pandas as pd\n",
    "# Process the dataframes for the runs.\n",
    "inst_FIR = Data_macro([pathFIR1,pathFIR2], col_names=\"B\", zero_field=True, units=\"cm-1\")\n",
    "avg_df = inst_FIR.Auto()\n",
    "dict[\"FIR\"] = avg_df\n",
    "```\n",
    "\n",
    "## Merging windows\n",
    "Once the dictionary ``dict`` is created, the windows can be merged into a single dataframe using the static method ``Treatment.merge_windows``. This takes each pair of dataframes in the dictionary and adjusts one so that the baselines in the overlapping region match. This can be done by adjusting the upper dataframe to match the baseline of the lower, or vice versa, depending on the variable ``high_to_low``. This variable can be input by the user as follows.\n",
    "```python\n",
    "df = Treatment.merge_windows(dict)\n",
    "```\n",
    "```\n",
    "Adjust baselines high to low? Y/N: \n",
    "```\n",
    "\n",
    "The user input can be bypassed by setting ``high_to_low`` to either ``True`` or ``False`` when calling the static method.\n",
    "\n",
    "The method returns a single dataframe which contains the merged data for all of the windows in the dictionary ``dict``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d27bc7",
   "metadata": {},
   "source": [
    "# Error handling\n",
    "The module may raise errors if expected conditions on the data or user inputs are not met. Here is a guide on how to interpret and avoid each error.\n",
    "\n",
    "## Value errors\n",
    "```No folders found in (path name) Check that folder names fit format.```\n",
    "\n",
    "This error occurs if none of the folders fit the expected format - ``FIR``, ``MIR``, ``HMIR``, ``LMIR``, or ``NIR``, not case sensitive. Check the folder names and rename if necessary. This can also occur if the input ``as_folder`` is set to ``True`` but the path entered leads directly to a list of files. Try changing ``as_folder`` to ``False``.\n",
    "\n",
    "```Unable to read columns from file names. Check that file names fit format.```\n",
    "\n",
    "This error occurs if none of the file names fit the expected format. Values of the magnetic field should be denoted as a string starting with ``a``, ending with ``T``, and with ``p`` replacing the decimal point. For example, ``a03p500T`` indicates a field strength of 3.5 T. Values of the temperature should be denoted as the last integer in the file name, excluding the last zero. \n",
    "\n",
    "```No files found in (path name)```\n",
    "\n",
    "This error occurs if a folder read by the module contains no files. Check that there are no empty folders with names matching the above list.\n",
    "\n",
    "## Other outputs\n",
    "```Invalid input: (description)``` or ```Unrecognised input```\n",
    "\n",
    "These errors occur if one of the variables input by a user does not fit the expected format. Check the table at the start of the demo for expected values.\n",
    "\n",
    "```Inconsistent indices in files (list of file names)```\n",
    "\n",
    "This warns the user if the index values of the files in a folder do not have the same length or do not agree. The module automatically interpolates to fill any missing values. If the output data shows artefacts of this interpolation, it may be worth checking through the files in this list for inconsistencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b680a59f",
   "metadata": {},
   "source": [
    "# Methods in the Treatment class\n",
    "\n",
    "The Treatment class contains a set of static methods which can be used for further treatment and processing of the data.\n",
    "\n",
    "## Derivatives\n",
    "\n",
    "The static method ``Treatment.derivative`` returns the derivative of the dataframe with respect to energy (if ``axis=0``) or magnetic field/temperature (if ``axis=1``). The arguments are described in the table below.\n",
    "\n",
    "| **Variable name** | data             | axis                                              | edge                                                               |\n",
    "| -----             | ----             | ----                                              | ----                                                               |\n",
    "| **Description**   | Spectral data    | Axis to derivative along: rows (0) or columns (1) | Handling of edges of range (refer to numpy.gradient documentation) |\n",
    "| **Type**          | pandas dataframe | int, defaults to 0                                | int, defaults to 1                                                 |\n",
    "\n",
    "## Baseline correction\n",
    "\n",
    "The static method ``Treatment.BS_correct`` returns a dataframe adjusted so that the baseline of the specified region is normalised to 1.\n",
    "\n",
    "| **Variable name** | data             | region                                         | \n",
    "| -----             | ----             | ----                                           |\n",
    "| **Description**   | Spectral data    | Region (e.g. energy interval) to be normalised | \n",
    "| **Type**          | pandas dataframe | list, tuple                                    | \n",
    "\n",
    "## Interpolation\n",
    "\n",
    "The static method ``Treatment.Interpolate`` returns a linearly interpolated dataframe according to the specified list of columns.\n",
    "\n",
    "| **Variable name** | data             | B0                | B                                                    |\n",
    "| -----             | ----             | ----              | ----                                                 |\n",
    "| **Description**   | Spectral data    | Original columns  | New columns to which the data should be interpolated |\n",
    "| **Type**          | pandas dataframe | numpy array, list | numpy array, list                                    |\n",
    "\n",
    "## Changing units\n",
    "\n",
    "The static method ``Treatment.Change_units`` changes the units of the index between ``cm-1``, ``meV``, and ``THz``. Note that the name of the index column must match the format expected for data processed by the ``Data_macro`` class.\n",
    "\n",
    "| **Variable name** | data                                  | units                     | \n",
    "| -----             | ----                                  | ----                      | \n",
    "| **Description**   | Spectral data processed by Data_macro | Units to set the index to | \n",
    "| **Type**          | pandas dataframe                      | \"cm-1\" or \"meV\" or \"THz\"  | \n",
    "\n",
    "## Baseline matching\n",
    "\n",
    "The static method ``Treatment.match_baseline`` takes two dataframes with overlapping windows, adjusts the baseline of one so that the baselines match at the region of overlap, and returns the adjusted dataframe only. The input ``adjust`` determines whether the dataframe with the higher window is adjusted to match the dataframe with the lower window or vice versa.\n",
    "\n",
    "| **Variable name** | df_low           | df_high          | adjust                                                    |\n",
    "| -----             | ----             | ----             | ----                                                      |\n",
    "| **Description**   | Spectral data    | Spectral data    | Method for adjusting baselines                            |\n",
    "| **Type**          | pandas dataframe | pandas dataframe | \"low_to_high\" or \"high_to_low\", defaults to \"low_to_high\" |\n",
    "\n",
    "## Smoothing\n",
    "\n",
    "The static method ``Treatment.SG_smooth`` returns a dataframe which has been smoothed using a Savitzky–Golay filter.\n",
    "\n",
    "| **Variable name** | data             | window                                         | poly                       |\n",
    "| -----             | ----             | ----                                           | ----                       |\n",
    "| **Description**   | Spectral data    | Number of coefficients in the smoothing window | Order of polynomial to fit |\n",
    "| **Type**          | pandas dataframe | int, odd                                       | int, smaller than window   |\n",
    "\n",
    "## Kramers-Kronig analysis \n",
    "\n",
    "The static method ``Treatment.Kramers_Kronig`` is described in full in a separate demo, but is listed here for completeness. \n",
    "\n",
    "This method takes a single column of a dataframe and parameters for high- and low-energy extrapolation, and returns a dataframe with five columns for the real part of the dielectric function \"er\", the imaginary part of the dielectric function \"ei\", the magnitude of reflectivity \"rf\", the real part of the optical conductivity \"sr\", and the phase of the reflectivity \"phase\". \n",
    "\n",
    "Note that the index should be in units of Hz. Note also that the calculation can be quite time-consuming and involves a multitude of diverging integrals.\n",
    "\n",
    "| **Variable name** | df                               | model                                                                                                        | low_lim                  | high_lim                           | below_fe                                                      | b                              |\n",
    "| -----             | ----                             | ----                                                                                                         | ----                     |  ----                              | ----                                                          | ----                           |\n",
    "| **Description**   | Spectral data                    | Model to be used for low-energy extrapolation                                                                | Limit of low-energy extrapolation | Limit of high-energy extrapolation | Check whether the energy range is below the plasma frequency | Constant for insulator model, or exponent for power law model |\n",
    "| **Type**          | pandas dataframe (single column) | \"Hagen-Rubens\", \"Insulator\", \"Power law\", \"Metal\", \"Marginal Fermi liquid\", \"Gorter-Casimir two-fluid model\", or \"Superconducting\" | float  | float                                | Boolean                                                       | float, defaults to None             |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
